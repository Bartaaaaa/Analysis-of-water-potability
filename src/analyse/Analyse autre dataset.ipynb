{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec23a82-41b1-4358-916d-c3f5240b3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0882e59-c8d9-4d30-9878-643d06e912d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "df_ = df.drop(['Potability', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Define x & y dataset\n",
    "y = df_[\"Potability_det\"]\n",
    "x = df_.drop([\"Potability_det\"], axis=1)\n",
    "\n",
    "dfeval = pd.read_csv('../../data/water_potability.csv')\n",
    "xeval = dfeval[\"Potability\"]\n",
    "yeval = dfeval.drop([\"Potability\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d69b5-42eb-4be1-b75b-d34fff612f5a",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c12556-297e-408d-9322-84ecd114267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8486647448887366\n"
     ]
    }
   ],
   "source": [
    "mean = x.mean(axis=0)\n",
    "x = x-mean\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_normalized = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cls = KNeighborsClassifier(n_neighbors=16)\n",
    "scores = cross_val_score(cls, x_normalized, y, cv=5)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1172ffb9-769c-43e2-86e4-87e7db2d75d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.8496732  0.88017429 0.82788671 0.84497817 0.84061135]\n",
      "Mean cross-validation score: 0.8486647448887366\n",
      "Accuracy: 0.5320735952262556\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.62      1200\n",
      "           1       0.41      0.38      0.40       811\n",
      "\n",
      "    accuracy                           0.53      2011\n",
      "   macro avg       0.51      0.51      0.51      2011\n",
      "weighted avg       0.53      0.53      0.53      2011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Charger les datasets\n",
    "\n",
    "y_train = df_[\"Potability_det\"]\n",
    "x_train = df_.drop([\"Potability_det\"], axis=1)\n",
    "# Préparer les données d'évaluation\n",
    "y_eval = dfeval[\"Potability\"]\n",
    "x_eval = dfeval.drop([\"Potability\"], axis=1)\n",
    "\n",
    "x_train = x_train.dropna()\n",
    "y_train = y_train[x_train.index]\n",
    "\n",
    "# Normaliser les données d'entraînement\n",
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "scaler = StandardScaler()\n",
    "x_train_normalized = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "\n",
    "# Validation croisée\n",
    "cls = KNeighborsClassifier(n_neighbors=16)\n",
    "scores = cross_val_score(cls, x_train_normalized, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean cross-validation score: {scores.mean()}\")\n",
    "\n",
    "# Entraîner le modèle KNN sur l'ensemble des données d'entraînement\n",
    "cls.fit(x_train_normalized, y_train)\n",
    "\n",
    "# Supprimer les lignes contenant des NaN dans les données d'évaluation\n",
    "x_eval = x_eval.dropna()\n",
    "y_eval = y_eval[x_eval.index]\n",
    "\n",
    "# Normaliser les données d'évaluation avec les mêmes paramètres que l'entraînement\n",
    "x_eval -= mean\n",
    "x_eval_normalized = pd.DataFrame(scaler.transform(x_eval), columns=x_eval.columns)\n",
    "\n",
    "# Prédire les labels pour les données d'évaluation\n",
    "y_pred = cls.predict(x_eval_normalized)\n",
    "\n",
    "# Évaluer le modèle sur les données d'évaluation\n",
    "accuracy = accuracy_score(y_eval, y_pred)\n",
    "report = classification_report(y_eval, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db71ff9b-08f0-42c9-8017-bb98ea498e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.64705882 0.63398693 0.64052288 0.66812227 0.64628821]\n",
      "Mean cross-validation score: 0.647195821560065\n",
      "Accuracy: 0.6727996021879662\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.93      0.77      1200\n",
      "           1       0.74      0.29      0.42       811\n",
      "\n",
      "    accuracy                           0.67      2011\n",
      "   macro avg       0.70      0.61      0.60      2011\n",
      "weighted avg       0.69      0.67      0.63      2011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "df_ = df.drop(['Potability_det', 'Unnamed: 0'], axis=1)\n",
    "df_\n",
    "\n",
    "\n",
    "y_train = df_[\"Potability\"]\n",
    "x_train = df_.drop([\"Potability\"], axis=1)\n",
    "# Préparer les données d'évaluation\n",
    "y_eval = dfeval[\"Potability\"]\n",
    "x_eval = dfeval.drop([\"Potability\"], axis=1)\n",
    "\n",
    "x_train = x_train.dropna()\n",
    "y_train = y_train[x_train.index]\n",
    "\n",
    "# Normaliser les données d'entraînement\n",
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "scaler = StandardScaler()\n",
    "x_train_normalized = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "\n",
    "# Validation croisée\n",
    "cls = KNeighborsClassifier(n_neighbors=16)\n",
    "scores = cross_val_score(cls, x_train_normalized, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean cross-validation score: {scores.mean()}\")\n",
    "\n",
    "# Entraîner le modèle KNN sur l'ensemble des données d'entraînement\n",
    "cls.fit(x_train_normalized, y_train)\n",
    "\n",
    "# Supprimer les lignes contenant des NaN dans les données d'évaluation\n",
    "x_eval = x_eval.dropna()\n",
    "y_eval = y_eval[x_eval.index]\n",
    "\n",
    "# Normaliser les données d'évaluation avec les mêmes paramètres que l'entraînement\n",
    "x_eval -= mean\n",
    "x_eval_normalized = pd.DataFrame(scaler.transform(x_eval), columns=x_eval.columns)\n",
    "\n",
    "# Prédire les labels pour les données d'évaluation\n",
    "y_pred = cls.predict(x_eval_normalized)\n",
    "\n",
    "# Évaluer le modèle sur les données d'évaluation\n",
    "accuracy = accuracy_score(y_eval, y_pred)\n",
    "report = classification_report(y_eval, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f06c6-8c90-48db-a431-95b8efc8d177",
   "metadata": {},
   "source": [
    "# TreeCLassifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3141b7a-6bae-42e4-bf4f-fdc8da1d98a3",
   "metadata": {},
   "source": [
    "# Data corrigé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8c5273-8c78-45a7-83af-62ffc765beff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m df_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPotability_det\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Division des données en ensembles d'entraînement et de test\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Suppression des valeurs manquantes dans les ensembles d'entraînement et de test\u001b[39;00m\n\u001b[0;32m     12\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "df_ = df.drop(['Potability', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Séparation des caractéristiques (X) et des labels (y)\n",
    "X = df_.drop(['Potability_det'], axis=1)\n",
    "y = df_['Potability_det']\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Suppression des valeurs manquantes dans les ensembles d'entraînement et de test\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "# Normalisation des données d'entraînement\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Normalisation des données de test avec les mêmes paramètres que l'entraînement\n",
    "X_test_normalized = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Initialiser le RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entraîner le modèle\n",
    "rf_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Charger les données d'évaluation\n",
    "dfeval = pd.read_csv('../../data/water_potability.csv')\n",
    "y_eval = dfeval[\"Potability\"]\n",
    "X_eval = dfeval.drop([\"Potability\"], axis=1)\n",
    "\n",
    "# Suppression des valeurs manquantes dans les données d'évaluation\n",
    "X_eval = X_eval.dropna()\n",
    "y_eval = y_eval[X_eval.index]\n",
    "\n",
    "# Normaliser les données d'évaluation avec les mêmes paramètres que l'entraînement\n",
    "X_eval_normalized = pd.DataFrame(scaler.transform(X_eval), columns=X_eval.columns)\n",
    "\n",
    "# Faire des prédictions sur les données d'évaluation\n",
    "y_pred_eval = rf_model.predict(X_eval_normalized)\n",
    "\n",
    "# Évaluer les performances du modèle sur les données d'évaluation\n",
    "accuracy_eval = accuracy_score(y_eval, y_pred_eval)\n",
    "classification_rep_eval = classification_report(y_eval, y_pred_eval)\n",
    "conf_matrix_eval = confusion_matrix(y_eval, y_pred_eval)\n",
    "\n",
    "print(f\"Accuracy on evaluation data: {accuracy_eval}\")\n",
    "print(\"Classification Report on evaluation data:\")\n",
    "print(classification_rep_eval)\n",
    "print(\"Confusion Matrix on evaluation data:\")\n",
    "print(conf_matrix_eval)\n",
    "dfeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cf615-b148-4c58-bbb4-0dd2a70046bf",
   "metadata": {},
   "source": [
    "# Data non corrigé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e75c1-20cc-41ac-aea9-8c67eddcb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "df_ = df.drop(['Potability_det', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Séparation des caractéristiques (X) et des labels (y)\n",
    "X = df_.drop(['Potability'], axis=1)\n",
    "y = df_['Potability']\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Suppression des valeurs manquantes dans les ensembles d'entraînement et de test\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "# Normalisation des données d'entraînement\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Normalisation des données de test avec les mêmes paramètres que l'entraînement\n",
    "X_test_normalized = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Initialiser le RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entraîner le modèle\n",
    "rf_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Charger les données d'évaluation\n",
    "dfeval = pd.read_csv('../../data/water_potability.csv')\n",
    "y_eval = dfeval[\"Potability\"]\n",
    "X_eval = dfeval.drop([\"Potability\"], axis=1)\n",
    "\n",
    "# Suppression des valeurs manquantes dans les données d'évaluation\n",
    "X_eval = X_eval.dropna()\n",
    "y_eval = y_eval[X_eval.index]\n",
    "\n",
    "# Normaliser les données d'évaluation avec les mêmes paramètres que l'entraînement\n",
    "X_eval_normalized = pd.DataFrame(scaler.transform(X_eval), columns=X_eval.columns)\n",
    "\n",
    "# Faire des prédictions sur les données d'évaluation\n",
    "y_pred_eval = rf_model.predict(X_eval_normalized)\n",
    "\n",
    "# Évaluer les performances du modèle sur les données d'évaluation\n",
    "accuracy_eval = accuracy_score(y_eval, y_pred_eval)\n",
    "classification_rep_eval = classification_report(y_eval, y_pred_eval)\n",
    "conf_matrix_eval = confusion_matrix(y_eval, y_pred_eval)\n",
    "\n",
    "print(f\"Accuracy on evaluation data: {accuracy_eval}\")\n",
    "print(\"Classification Report on evaluation data:\")\n",
    "print(classification_rep_eval)\n",
    "print(\"Confusion Matrix on evaluation data:\")\n",
    "print(conf_matrix_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec871bd-ea48-417e-8185-5df369a4ed28",
   "metadata": {},
   "source": [
    "# Deuxieme dataset de ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a0259-6a67-4e63-a682-f794fbbdaeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "df_ = df.drop(['Potability', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Séparation des caractéristiques (X) et des labels (y)\n",
    "X = df_.drop(['Potability_det'], axis=1)\n",
    "y = df_['Potability_det']\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Suppression des valeurs manquantes dans les ensembles d'entraînement et de test\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "# Normalisation des données d'entraînement\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Normalisation des données de test avec les mêmes paramètres que l'entraînement\n",
    "X_test_normalized = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Initialiser le RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entraîner le modèle\n",
    "rf_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Charger les données d'évaluation\n",
    "dfeval = pd.read_csv('../../data/water_potability2.csv')\n",
    "y_eval = dfeval[\"Potability\"]\n",
    "X_eval = dfeval.drop([\"Potability\"], axis=1)\n",
    "\n",
    "# Suppression des valeurs manquantes dans les données d'évaluation\n",
    "X_eval = X_eval.dropna()\n",
    "y_eval = y_eval[X_eval.index]\n",
    "\n",
    "# Normaliser les données d'évaluation avec les mêmes paramètres que l'entraînement\n",
    "X_eval_normalized = pd.DataFrame(scaler.transform(X_eval), columns=X_eval.columns)\n",
    "\n",
    "# Faire des prédictions sur les données d'évaluation\n",
    "y_pred_eval = rf_model.predict(X_eval_normalized)\n",
    "\n",
    "# Évaluer les performances du modèle sur les données d'évaluation\n",
    "accuracy_eval = accuracy_score(y_eval, y_pred_eval)\n",
    "classification_rep_eval = classification_report(y_eval, y_pred_eval)\n",
    "conf_matrix_eval = confusion_matrix(y_eval, y_pred_eval)\n",
    "\n",
    "print(f\"Accuracy on evaluation data: {accuracy_eval}\")\n",
    "print(\"Classification Report on evaluation data:\")\n",
    "print(classification_rep_eval)\n",
    "print(\"Confusion Matrix on evaluation data:\")\n",
    "print(conf_matrix_eval)\n",
    "dfeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923d269-0b56-4991-8354-3f33734aa664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "df_ = df.drop(['Potability_det', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Séparation des caractéristiques (X) et des labels (y)\n",
    "X = df_.drop(['Potability'], axis=1)\n",
    "y = df_['Potability']\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Suppression des valeurs manquantes dans les ensembles d'entraînement et de test\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "# Normalisation des données d'entraînement\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Normalisation des données de test avec les mêmes paramètres que l'entraînement\n",
    "X_test_normalized = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Initialiser le RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entraîner le modèle\n",
    "rf_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Charger les données d'évaluation\n",
    "dfeval = pd.read_csv('../../data/water_potability2.csv')\n",
    "y_eval = dfeval[\"Potability\"]\n",
    "X_eval = dfeval.drop([\"Potability\"], axis=1)\n",
    "\n",
    "# Suppression des valeurs manquantes dans les données d'évaluation\n",
    "X_eval = X_eval.dropna()\n",
    "y_eval = y_eval[X_eval.index]\n",
    "\n",
    "# Normaliser les données d'évaluation avec les mêmes paramètres que l'entraînement\n",
    "X_eval_normalized = pd.DataFrame(scaler.transform(X_eval), columns=X_eval.columns)\n",
    "\n",
    "# Faire des prédictions sur les données d'évaluation\n",
    "y_pred_eval = rf_model.predict(X_eval_normalized)\n",
    "\n",
    "# Évaluer les performances du modèle sur les données d'évaluation\n",
    "accuracy_eval = accuracy_score(y_eval, y_pred_eval)\n",
    "classification_rep_eval = classification_report(y_eval, y_pred_eval)\n",
    "conf_matrix_eval = confusion_matrix(y_eval, y_pred_eval)\n",
    "\n",
    "print(f\"Accuracy on evaluation data: {accuracy_eval}\")\n",
    "print(\"Classification Report on evaluation data:\")\n",
    "print(classification_rep_eval)\n",
    "print(\"Confusion Matrix on evaluation data:\")\n",
    "print(conf_matrix_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1594692-8152-404b-9ffc-5bf062f5b09d",
   "metadata": {},
   "source": [
    "# ACP TREE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562771e8-191a-487e-9553-fb6de58aa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Read the data\n",
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "\n",
    "# Step 2: Drop unnecessary columns\n",
    "df_ = df.drop(['Potability', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Step 3: Center the data\n",
    "mean = df_.mean(axis=0)\n",
    "df_centered = df_ - mean\n",
    "\n",
    "# Step 4: Standardize the data\n",
    "scaler_s = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler_s.fit_transform(df_centered.drop('Potability_det', axis=1)), columns=df_centered.columns[:-1])\n",
    "\n",
    "# Step 5: PCA transformation\n",
    "cls_standardized = PCA(n_components=2)\n",
    "pcs_df_standardized = cls_standardized.fit_transform(df_standardized)\n",
    "\n",
    "# Step 6: Combine PCA results with 'Potability_det'\n",
    "pcs_df = pd.DataFrame(data=pcs_df_standardized, columns=['PC1', 'PC2'])\n",
    "pcs_df['Potability_det'] = df_['Potability_det'].values\n",
    "\n",
    "# Step 7: Plot the first two principal components with hue\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Potability_det', data=pcs_df, palette='viridis', alpha=0.7)\n",
    "plt.title(\"Scatter Plot of the First Two Principal Components\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359995c-c49e-4091-a63a-701db9a01850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_decision_boundary\n",
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "\n",
    "# Step 2: Drop unnecessary columns\n",
    "df_ = df.drop(['Potability', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Step 3: Center the data\n",
    "mean = df_.mean(axis=0)\n",
    "df_centered = df_ - mean\n",
    "\n",
    "# Step 4: Standardize the data\n",
    "scaler_s = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler_s.fit_transform(df_centered.drop('Potability_det', axis=1)), columns=df_centered.columns[:-1])\n",
    "\n",
    "# Step 5: PCA transformation\n",
    "cls_standardized = PCA(n_components=2)\n",
    "pcs_df_standardized = cls_standardized.fit_transform(df_standardized)\n",
    "\n",
    "# Step 6: Combine PCA results with 'Potability_det'\n",
    "pcs_df = pd.DataFrame(data=pcs_df_standardized, columns=['PC1', 'PC2'])\n",
    "pcs_df['Potability_det'] = df_['Potability_det'].values\n",
    "\n",
    "# Step 7: Split the data into training and testing sets\n",
    "X = pcs_df[['PC1', 'PC2']]\n",
    "y = pcs_df['Potability_det']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Make predictions and calculate accuracy\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of Random Forest Classifier: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b86f183-d8d6-49c3-bf02-7f235f1eb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='PC1', y='PC2', hue='Potability_det', data=pcs_df_standardized, palette='viridis', alpha=0.7)\n",
    "add_decision_boundary(cls)\n",
    "plt.title(\"Scatter Plot of the First Two Principal Components\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c440b-5acc-4740-b309-1e53f2a2065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/data_preprocessed.csv')\n",
    "\n",
    "# Step 2: Drop unnecessary columns\n",
    "df_ = df.drop(['Potability', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Step 3: Center the data\n",
    "mean = df_.mean(axis=0)\n",
    "df_centered = df_ - mean\n",
    "\n",
    "# Step 4: Standardize the data\n",
    "scaler_s = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler_s.fit_transform(df_centered.drop('Potability_det', axis=1)), columns=df_centered.columns[:-1])\n",
    "\n",
    "# Step 5: PCA transformation\n",
    "cls_standardized = PCA(n_components=2)\n",
    "pcs_df_standardized = cls_standardized.fit_transform(df_standardized)\n",
    "\n",
    "# Step 6: Combine PCA results with 'Potability_det'\n",
    "pcs_df = pd.DataFrame(data=pcs_df_standardized, columns=['PC1', 'PC2'])\n",
    "pcs_df['Potability_det'] = df_['Potability_det'].values\n",
    "\n",
    "# Step 7: Split the data into training and testing sets\n",
    "X = pcs_df[['PC1', 'PC2']]\n",
    "y = pcs_df['Potability_det']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Make predictions and calculate accuracy\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of Random Forest Classifier: {accuracy:.2f}\")\n",
    "\n",
    "# Step 10: Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "add_decision_boundary(cls_standardized)\n",
    "plt.title(\"Scatter Plot of the First Two Principal Components with Decision Boundary\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebd53c-99ee-4d33-8620-9054ef47c7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
